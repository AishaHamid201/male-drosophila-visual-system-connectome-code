{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a37d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T17:21:39.563345Z",
     "iopub.status.busy": "2024-10-24T17:21:39.562412Z",
     "iopub.status.idle": "2024-10-24T17:21:43.478372Z",
     "shell.execute_reply": "2024-10-24T17:21:43.477458Z",
     "shell.execute_reply.started": "2024-10-24T17:21:39.563291Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from neuprint import NeuronCriteria as NC, merge_neuron_properties\n",
    "from neuprint.queries import fetch_neurons, fetch_adjacencies\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_ROOT = Path(find_dotenv()).parent\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT.joinpath('src')))\n",
    "print(f\"Project root directory: {PROJECT_ROOT}\")\n",
    "\n",
    "from utils import olc_client\n",
    "from utils.clustering_functions import cluster_neurons, generate_clustering_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767a436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T17:21:48.038917Z",
     "iopub.status.busy": "2024-10-24T17:21:48.038341Z",
     "iopub.status.idle": "2024-10-24T17:21:48.265786Z",
     "shell.execute_reply": "2024-10-24T17:21:48.264883Z",
     "shell.execute_reply.started": "2024-10-24T17:21:48.038892Z"
    }
   },
   "outputs": [],
   "source": [
    "c = olc_client.connect(verbose=True)\n",
    "\n",
    "data_dir = PROJECT_ROOT / 'results' / 'clustering' / 'clustering_results_for_figures'\n",
    "cache_dir = PROJECT_ROOT / 'cache' / 'clustering'\n",
    "\n",
    "data_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_type, exclude_from_clustering, fragment_type_dict = generate_clustering_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(fragment_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a86c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T17:22:35.243878Z",
     "iopub.status.busy": "2024-10-24T17:22:35.243592Z",
     "iopub.status.idle": "2024-10-24T17:22:57.200023Z",
     "shell.execute_reply": "2024-10-24T17:22:57.198986Z",
     "shell.execute_reply.started": "2024-10-24T17:22:35.243851Z"
    }
   },
   "outputs": [],
   "source": [
    "## list of bodyIds to cluster (here: based on region and synapse numbers and whether the\n",
    "#  body has type or instance name)\n",
    "\n",
    "criteria = NC(rois=['ME(R)', 'LO(R)', 'LOP(R)','AME(R)','LA(R)'], roi_req='any')\n",
    "neurons_all, _ = fetch_neurons(criteria)\n",
    "## the >100 threshold is ok for most OL cells except a few near the edges\n",
    "neurons_all = neurons_all[neurons_all.synweight > 100]\n",
    "\n",
    "neuron_selection = list(set(neurons_all.bodyId.tolist( ) + list(bid_type.keys())))\n",
    "display(f\"Number of selected neurons: {len(neuron_selection)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611686cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T17:22:57.201794Z",
     "iopub.status.busy": "2024-10-24T17:22:57.201400Z",
     "iopub.status.idle": "2024-10-24T17:22:58.992617Z",
     "shell.execute_reply": "2024-10-24T17:22:58.991569Z",
     "shell.execute_reply.started": "2024-10-24T17:22:57.201764Z"
    }
   },
   "outputs": [],
   "source": [
    "## get up- and downstream synaptic partners of all bodies in neuron_selection\n",
    "\n",
    "cache_target_fn = cache_dir / \"ROL_targets_df_neuprint_only_102023_v11.pickle\"\n",
    "\n",
    "if cache_target_fn.is_file():\n",
    "    ## load dataframes with connection data (faster than getting these from neuprint\n",
    "    ## and soon no further changes will be expected for the right optic lobe for now)\n",
    "    conn_df_targets = pd.read_pickle(cache_target_fn)\n",
    "else:\n",
    "    criteria = NC(bodyId=neuron_selection)\n",
    "    neuron_df1, conn_df1 = fetch_adjacencies(criteria, None, include_nonprimary=False) # targets\n",
    "    conn_df_targets = merge_neuron_properties(neuron_df1, conn_df1)\n",
    "    del neuron_df1, conn_df1\n",
    "    ## save dataframes with connection data (reload is faster than getting these from neuprint)\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    conn_df_targets.to_pickle(cache_target_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e838934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T17:22:58.994481Z",
     "iopub.status.busy": "2024-10-24T17:22:58.994001Z",
     "iopub.status.idle": "2024-10-24T17:23:00.772212Z",
     "shell.execute_reply": "2024-10-24T17:23:00.771108Z",
     "shell.execute_reply.started": "2024-10-24T17:22:58.994448Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cache_input_fn  = cache_dir / \"ROL_inputs_df_neuprint_only_102023_v11.pickle\"\n",
    "\n",
    "if cache_input_fn.is_file():\n",
    "    ## load dataframes with connection data (faster than getting these from neuprint\n",
    "    ## and soon no further changes will be expected for the right optic lobe for now)\n",
    "    conn_df_inputs = pd.read_pickle(cache_input_fn)\n",
    "else:\n",
    "    criteria = NC(bodyId=neuron_selection)\n",
    "    neuron_df2, conn_df2 = fetch_adjacencies(None, criteria, include_nonprimary=False) # inputs\n",
    "    conn_df_inputs = merge_neuron_properties(neuron_df2, conn_df2)\n",
    "    del neuron_df2, conn_df2\n",
    "    ## save dataframes with connection data (reload is faster than getting these from neuprint)\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    conn_df_inputs.to_pickle(cache_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f83b6",
   "metadata": {},
   "source": [
    "## clustering examples\n",
    "\n",
    "### example 1\n",
    "\n",
    "clustering a subset of neurons\n",
    "\n",
    "to run this for the full optic lobe, set `cell_list=neuron_selection` (see above)\n",
    "    and number_of_clusters to e.g. 600\n",
    "\n",
    "example: set of cell types with one cell per column shown in Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38749a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_selection = [\n",
    "    'L1', 'L2', 'L3', 'L5'\n",
    "  , 'Mi1', 'Mi4', 'Mi9'\n",
    "  , 'C2', 'C3', 'T1'\n",
    "  , 'Tm1', 'Tm2', 'Tm4', 'Tm9', 'Tm20'\n",
    "]\n",
    "\n",
    "cells_per_cluster_by_type = cluster_neurons(\n",
    "    type_selection=type_selection\n",
    "  , bid_type=bid_type\n",
    "  , exclude_from_clustering=exclude_from_clustering\n",
    "  , fragment_type_dict=fragment_type_dict\n",
    "  , input_df=conn_df_inputs\n",
    "  , output_df=conn_df_targets\n",
    "  , number_of_clusters=len(type_selection) # one cluster per type in this case\n",
    ")\n",
    "\n",
    "cells_per_cluster_by_type.to_csv(data_dir / 'clustering_Fig2d.csv')\n",
    "\n",
    "display(cells_per_cluster_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546b624",
   "metadata": {},
   "source": [
    "### example 2\n",
    "\n",
    "clustering example: cell types with synapses only in ME(R) (Dm,Cm,Pm and Mi cells)\n",
    "    and at least 10 instances (cells) per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_selection = (\n",
    "    list({\n",
    "        cell_type for cell_type in bid_type.values() \\\n",
    "            if cell_type.startswith(('Dm', 'Cm', 'Pm', 'Mi'))\n",
    "    })\n",
    ")\n",
    "\n",
    "# cell types with at least 10 instances\n",
    "type_selection = [\n",
    "    cell_type for cell_type in type_selection \\\n",
    "        if len(\n",
    "            [bodyId for bodyId in bid_type.keys() if bid_type[bodyId] == cell_type]\n",
    "        )>=10]\n",
    "\n",
    "# exclude named fragments\n",
    "type_selection = [cell_type for cell_type in type_selection if not 'fragment' in cell_type]\n",
    "\n",
    "cells_per_cluster_by_type = cluster_neurons(\n",
    "    type_selection=type_selection\n",
    "  , bid_type=bid_type\n",
    "  , exclude_from_clustering=exclude_from_clustering\n",
    "  , fragment_type_dict=fragment_type_dict\n",
    "  , input_df=conn_df_inputs\n",
    "  , output_df=conn_df_targets\n",
    "  , number_of_clusters=80\n",
    ")\n",
    "\n",
    "cells_per_cluster_by_type.to_csv(data_dir / 'clustering_ED_Fig3.csv')\n",
    "\n",
    "display(cells_per_cluster_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e4ca7",
   "metadata": {},
   "source": [
    "### example 3\n",
    "\n",
    "clustering example: clustering cells without using the connections to selected cell types\n",
    "\n",
    "Examples: Pairs of Tm5a/Tm5b/Tm29 and Dm8a/Dm8b without using synapses with R7 and R8 types,\n",
    "    Dm8/Dm8b, Tm5a/Tm5b and Tm29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb41637",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_selections = [\n",
    "    ['Tm5a', 'Tm5b'], ['Tm5a', 'Tm5b']\n",
    "  , ['Tm5a', 'Tm29'], ['Tm29', 'Tm5b']\n",
    "  , ['Dm8a', 'Dm8b']\n",
    "]\n",
    "exclude_R7_R8_Tm5ab_Dm8ab = [False, True, True, True, True]\n",
    "\n",
    "\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "for type_selection, exclude in zip(type_selections, exclude_R7_R8_Tm5ab_Dm8ab):\n",
    "\n",
    "    type_exclude = exclude_from_clustering\n",
    "    if exclude:\n",
    "        type_exclude = exclude_from_clustering \\\n",
    "          + ['R8p', 'R7p', 'R8y', 'R8y', 'R8d', 'R7d', 'Dm8a', 'Dm8b', 'Tm5a', 'Tm5b']\n",
    "    cells_per_cluster_by_type = cluster_neurons(\n",
    "        type_selection=type_selection\n",
    "      , bid_type=bid_type\n",
    "      , exclude_from_clustering=type_exclude\n",
    "      , fragment_type_dict=fragment_type_dict\n",
    "      , input_df=conn_df_inputs\n",
    "      , output_df=conn_df_targets\n",
    "      , number_of_clusters=2\n",
    "    )\n",
    "    cells_per_cluster_by_type['cell_types'] = \", \".join(type_selection)\n",
    "    cells_per_cluster_by_type['R7R8_Tm5b_Dm8ab_connections_excluded'] = exclude\n",
    "    combined_results = pd.concat([combined_results, cells_per_cluster_by_type])\n",
    "\n",
    "\n",
    "combined_results.to_csv(data_dir / 'clustering_ED_Fig5.csv')\n",
    "\n",
    "display(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65a619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
